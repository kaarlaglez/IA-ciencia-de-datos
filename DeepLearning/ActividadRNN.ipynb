{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad - Redes Neuronales Recurrentes\n",
        "Karla González Sánchez | A01541526\n",
        "\n",
        "Martes 7 de noviembre de 2023"
      ],
      "metadata": {
        "id": "NQE8uGNPcFaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "VfMBJdGtUX_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descarga de datos"
      ],
      "metadata": {
        "id": "uVqkM5FPV0yz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MztjelYUBwO"
      },
      "outputs": [],
      "source": [
        "# Abre y lee el archivo \"darwin.txt\" que contiene el texto que se desea analizar\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/NLP/darwin.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Longitud del texto:        {} carácteres'.format(len(text)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n",
        "print (vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdALDydAVHYW",
        "outputId": "ede1d0bb-7df8-46d4-cced-9988ddc13a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del texto:        971489 carácteres\n",
            "El texto está compuesto de estos 106 carácteres:\n",
            "['\\n', '\\x0c', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', '¾', 'Æ', '×', 'ä', 'æ', 'ë', 'ö', 'ü', 'œ', '—', '‘', '’', '“', '”', '•', '™', '√', 'ﬀ', 'ﬁ', 'ﬂ', 'ﬃ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenización inversa del vocabulario"
      ],
      "metadata": {
        "id": "0eQ3xuY2V50L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf-sS9SoVTOW",
        "outputId": "91b8de16-336d-4d81-8686-99b6f357aac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  '\\n':   0,\n",
            "  '\\x0c':   1,\n",
            "  ' ' :   2,\n",
            "  '!' :   3,\n",
            "  '\"' :   4,\n",
            "  '#' :   5,\n",
            "  '$' :   6,\n",
            "  '%' :   7,\n",
            "  '&' :   8,\n",
            "  \"'\" :   9,\n",
            "  '(' :  10,\n",
            "  ')' :  11,\n",
            "  '*' :  12,\n",
            "  ',' :  13,\n",
            "  '-' :  14,\n",
            "  '.' :  15,\n",
            "  '/' :  16,\n",
            "  '0' :  17,\n",
            "  '1' :  18,\n",
            "  '2' :  19,\n",
            "  '3' :  20,\n",
            "  '4' :  21,\n",
            "  '5' :  22,\n",
            "  '6' :  23,\n",
            "  '7' :  24,\n",
            "  '8' :  25,\n",
            "  '9' :  26,\n",
            "  ':' :  27,\n",
            "  ';' :  28,\n",
            "  '?' :  29,\n",
            "  'A' :  30,\n",
            "  'B' :  31,\n",
            "  'C' :  32,\n",
            "  'D' :  33,\n",
            "  'E' :  34,\n",
            "  'F' :  35,\n",
            "  'G' :  36,\n",
            "  'H' :  37,\n",
            "  'I' :  38,\n",
            "  'J' :  39,\n",
            "  'K' :  40,\n",
            "  'L' :  41,\n",
            "  'M' :  42,\n",
            "  'N' :  43,\n",
            "  'O' :  44,\n",
            "  'P' :  45,\n",
            "  'Q' :  46,\n",
            "  'R' :  47,\n",
            "  'S' :  48,\n",
            "  'T' :  49,\n",
            "  'U' :  50,\n",
            "  'V' :  51,\n",
            "  'W' :  52,\n",
            "  'X' :  53,\n",
            "  'Y' :  54,\n",
            "  'Z' :  55,\n",
            "  '[' :  56,\n",
            "  ']' :  57,\n",
            "  'a' :  58,\n",
            "  'b' :  59,\n",
            "  'c' :  60,\n",
            "  'd' :  61,\n",
            "  'e' :  62,\n",
            "  'f' :  63,\n",
            "  'g' :  64,\n",
            "  'h' :  65,\n",
            "  'i' :  66,\n",
            "  'j' :  67,\n",
            "  'k' :  68,\n",
            "  'l' :  69,\n",
            "  'm' :  70,\n",
            "  'n' :  71,\n",
            "  'o' :  72,\n",
            "  'p' :  73,\n",
            "  'q' :  74,\n",
            "  'r' :  75,\n",
            "  's' :  76,\n",
            "  't' :  77,\n",
            "  'u' :  78,\n",
            "  'v' :  79,\n",
            "  'w' :  80,\n",
            "  'x' :  81,\n",
            "  'y' :  82,\n",
            "  'z' :  83,\n",
            "  '°' :  84,\n",
            "  '¾' :  85,\n",
            "  'Æ' :  86,\n",
            "  '×' :  87,\n",
            "  'ä' :  88,\n",
            "  'æ' :  89,\n",
            "  'ë' :  90,\n",
            "  'ö' :  91,\n",
            "  'ü' :  92,\n",
            "  'œ' :  93,\n",
            "  '—' :  94,\n",
            "  '‘' :  95,\n",
            "  '’' :  96,\n",
            "  '“' :  97,\n",
            "  '”' :  98,\n",
            "  '•' :  99,\n",
            "  '™' : 100,\n",
            "  '√' : 101,\n",
            "  'ﬀ' : 102,\n",
            "  'ﬁ' : 103,\n",
            "  'ﬂ' : 104,\n",
            "  'ﬃ' : 105,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Covertir texto a numeros"
      ],
      "metadata": {
        "id": "LDYENllrWArz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "print ('texto: {}'.format(repr(text[:50])))\n",
        "print ('{}'.format(repr(text_as_int[:50])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlwQ2NoqViRa",
        "outputId": "6e136bf3-b07c-4db1-bd68-6781c5c38557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto: 'The Project Gutenberg eBook of On the Origin of Sp'\n",
            "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
            "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 44, 71,  2,\n",
            "       77, 65, 62,  2, 44, 75, 66, 64, 66, 71,  2, 72, 63,  2, 48, 73])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparar los datos"
      ],
      "metadata": {
        "id": "08PgwVmTWF4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "a9bGLebDVoGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUGjrCb5WQHh",
        "outputId": "af10e6dd-df8b-4f69-fde3-02da53f476ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'The Project Gutenberg eBook of On the Origin of Species by Means of Natural Selection\\n    This ebook '\n",
            "'is for the use of anyone anywhere in the United States and most other parts of the world at no\\n    co'\n",
            "'st and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the t'\n",
            "'erms\\n    of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If'\n",
            "' you are not\\n    located in the United States, you will have to check the laws of the country where y'\n",
            "'ou are located before\\n    using this eBook.\\n\\n    Title: On the Origin of Species by Means of Natural '\n",
            "'Selection\\n\\n         Author: Charles Darwin\\n\\n    Release date: September 25, 2007 [eBook #22764]\\n     '\n",
            "'       Most recently updated: March 12, 2021\\n\\n    Language: English\\n\\n\\n    *** START OF THE PROJECT GU'\n",
            "'TENBERG EBOOK ON THE ORIGIN OF SPECIES BY MEANS OF\\n                                 NATURAL SELECTION'\n",
            "' ***\\n\\n\\n\\n\\n There are several editions of this ebook in the Project Gutenberg collection. Various chara'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "ryc_ciW2WaF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjIHG4QhWdf0",
        "outputId": "4c3a1095-388e-4fa6-c3ac-0b76da00de6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  'The Project Gutenberg eBook of On the Origin of Species by Means of Natural Selection\\n    This ebook'\n",
            "Target data: 'he Project Gutenberg eBook of On the Origin of Species by Means of Natural Selection\\n    This ebook '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print (dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLvAJG1tWs9y",
        "outputId": "3aa4ce16-2367-497c-b5ce-2366bd3de81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construir modelo"
      ],
      "metadata": {
        "id": "5W4VadkFW793"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "o1Jf4NO3W-Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "DOx6lO30XI1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "qjrpMtLQXM52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQtKH_S_XPwm",
        "outputId": "87dd0f69-41f8-4f63-cdfe-d19e0f78a12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           27136     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 106)           108650    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5382762 (20.53 MB)\n",
            "Trainable params: 5382762 (20.53 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "b5XEmwqUXXLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "h5R3vHpIXYw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "pxUdh5q0Xjq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "E71JB0BzXl8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=50\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NX6sBRqXpJj",
        "outputId": "555453da-08ff-4a94-9779-c152e28f6742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "150/150 [==============================] - 20s 74ms/step - loss: 2.6517\n",
            "Epoch 2/50\n",
            "150/150 [==============================] - 13s 68ms/step - loss: 1.8806\n",
            "Epoch 3/50\n",
            "150/150 [==============================] - 12s 69ms/step - loss: 1.5210\n",
            "Epoch 4/50\n",
            "150/150 [==============================] - 12s 67ms/step - loss: 1.3449\n",
            "Epoch 5/50\n",
            "150/150 [==============================] - 12s 68ms/step - loss: 1.2490\n",
            "Epoch 6/50\n",
            "150/150 [==============================] - 12s 70ms/step - loss: 1.1846\n",
            "Epoch 7/50\n",
            "150/150 [==============================] - 12s 69ms/step - loss: 1.1383\n",
            "Epoch 8/50\n",
            "150/150 [==============================] - 12s 71ms/step - loss: 1.0989\n",
            "Epoch 9/50\n",
            "150/150 [==============================] - 12s 72ms/step - loss: 1.0656\n",
            "Epoch 10/50\n",
            "150/150 [==============================] - 12s 71ms/step - loss: 1.0349\n",
            "Epoch 11/50\n",
            "150/150 [==============================] - 12s 71ms/step - loss: 1.0065\n",
            "Epoch 12/50\n",
            "150/150 [==============================] - 12s 71ms/step - loss: 0.9806\n",
            "Epoch 13/50\n",
            "150/150 [==============================] - 12s 72ms/step - loss: 0.9538\n",
            "Epoch 14/50\n",
            "150/150 [==============================] - 12s 72ms/step - loss: 0.9279\n",
            "Epoch 15/50\n",
            "150/150 [==============================] - 12s 73ms/step - loss: 0.9034\n",
            "Epoch 16/50\n",
            "150/150 [==============================] - 13s 74ms/step - loss: 0.8786\n",
            "Epoch 17/50\n",
            "150/150 [==============================] - 13s 74ms/step - loss: 0.8539\n",
            "Epoch 18/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.8293\n",
            "Epoch 19/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.8036\n",
            "Epoch 20/50\n",
            "150/150 [==============================] - 13s 73ms/step - loss: 0.7799\n",
            "Epoch 21/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.7553\n",
            "Epoch 22/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.7303\n",
            "Epoch 23/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.7080\n",
            "Epoch 24/50\n",
            "150/150 [==============================] - 13s 76ms/step - loss: 0.6842\n",
            "Epoch 25/50\n",
            "150/150 [==============================] - 13s 76ms/step - loss: 0.6617\n",
            "Epoch 26/50\n",
            "150/150 [==============================] - 13s 78ms/step - loss: 0.6410\n",
            "Epoch 27/50\n",
            "150/150 [==============================] - 13s 76ms/step - loss: 0.6197\n",
            "Epoch 28/50\n",
            "150/150 [==============================] - 13s 79ms/step - loss: 0.5992\n",
            "Epoch 29/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.5818\n",
            "Epoch 30/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.5647\n",
            "Epoch 31/50\n",
            "150/150 [==============================] - 13s 76ms/step - loss: 0.5483\n",
            "Epoch 32/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.5319\n",
            "Epoch 33/50\n",
            "150/150 [==============================] - 12s 73ms/step - loss: 0.5172\n",
            "Epoch 34/50\n",
            "150/150 [==============================] - 13s 74ms/step - loss: 0.5028\n",
            "Epoch 35/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.4911\n",
            "Epoch 36/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.4798\n",
            "Epoch 37/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.4670\n",
            "Epoch 38/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.4581\n",
            "Epoch 39/50\n",
            "150/150 [==============================] - 14s 74ms/step - loss: 0.4481\n",
            "Epoch 40/50\n",
            "150/150 [==============================] - 14s 74ms/step - loss: 0.4395\n",
            "Epoch 41/50\n",
            "150/150 [==============================] - 13s 75ms/step - loss: 0.4316\n",
            "Epoch 42/50\n",
            "150/150 [==============================] - 13s 73ms/step - loss: 0.4245\n",
            "Epoch 43/50\n",
            "150/150 [==============================] - 13s 73ms/step - loss: 0.4173\n",
            "Epoch 44/50\n",
            "150/150 [==============================] - 14s 74ms/step - loss: 0.4104\n",
            "Epoch 45/50\n",
            "150/150 [==============================] - 14s 75ms/step - loss: 0.4062\n",
            "Epoch 46/50\n",
            "150/150 [==============================] - 14s 75ms/step - loss: 0.3974\n",
            "Epoch 47/50\n",
            "150/150 [==============================] - 13s 74ms/step - loss: 0.3925\n",
            "Epoch 48/50\n",
            "150/150 [==============================] - 13s 73ms/step - loss: 0.3883\n",
            "Epoch 49/50\n",
            "150/150 [==============================] - 14s 73ms/step - loss: 0.3828\n",
            "Epoch 50/50\n",
            "150/150 [==============================] - 14s 75ms/step - loss: 0.3777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generación de texto"
      ],
      "metadata": {
        "id": "27JsGwE4XuOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "5yPR3wNCYIXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### temperatura de 0.5"
      ],
      "metadata": {
        "id": "qzPbrfEXaLbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 500\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "\n",
        "  temperature = 0.5\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "_wxlRoylYI-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"species\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts1GsFykYLtB",
        "outputId": "e9dfbf4f-33e9-4870-fb1a-e16b897fb6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "species, or of any recognisable degree of\n",
            "utility of constitution, with which the great diﬃculty lies in the working of a perfectly ecies; and will then rank when the requirements of natural selection consider which is very great. If we have seen in the case of animals with simple in a few days, they could not be found on the heath. The eﬀect on the\n",
            "insect at a quicker rate that only a single case, that of working\n",
            "or sterile ants. How the workers or species are rendered to a large extent deﬁned and dis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"animals\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq-zQvQ4YODp",
        "outputId": "a0c40d58-e460-40a1-a982-a191517a0f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "animals, it\n",
            "seems to me that\n",
            "the theory of natural selection may be extended. In Europe we have the plainest evidence in great fossiliferous formations were deposited during periods of subsidence. These periods will have been ample figh in homologous organs, the other forms in the same manner; then, on the plants of the same variety may be said to have been recorded. These facts can be\n",
            "explained, as follows, on the view of descent with modification.\n",
            "It is commonly adapted to each other. It is a case of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperatura de 0.1"
      ],
      "metadata": {
        "id": "KmEp83wjaTUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 500\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "\n",
        "  temperature = 0.1\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "QOMDVlkPaYiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"species\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSiytkgMaZwW",
        "outputId": "ea9b5435-127b-4c46-dcdc-28807015988a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "species of a genus having\n",
            "descended from a common parent and many individuals will have had a single species of bat having been developed into trees, &c.,—seem to me to accord better with\n",
            "the view of oceanic islands, whilst the most\n",
            "isolated islands possessed by the Melipona,\n",
            "and in the period\n",
            "muse insects in the waters of the sea. If two great regions had\n",
            "been for a long period favourable conditions, is innately variable. That is, the colour was more closely related to\n",
            "each other, and\n",
            "with the several\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"animals\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln6dfTudabdq",
        "outputId": "748c5634-e35c-45a4-e21d-46f13c22efad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "animals, it\n",
            "seems to me well enabled the same species in Switzerland, I can see no limit to this power, in\n",
            "species, that mammals have not been able to migrate to\n",
            "the stamens of the same species. I should never have expeared within the same class, that we might be led to look at\n",
            "these facts as necessarily accumulated at wide and true time of descent. These cirripedes can act on each shoulder in comparison with the same species when self-fertilised, sometimes depends.\n",
            "The practicate seems to have been fo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperatura de 1"
      ],
      "metadata": {
        "id": "-2uqGTWzadvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 500\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "\n",
        "  temperature = 1\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "lKYsDnj5aje9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"species\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI8Ev8q1apP6",
        "outputId": "26c81ba3-3218-4ca8-9446-9d7681f2f999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "species, so that they have changed hind legs, and\n",
            "even in several quarters of the world, we cannot my, make err from the waters.\n",
            "Hence, we can here give only the fore-less not like the planer only with skin the female to the male mammals, from the Project Gutenberg™ electronic work, yet keep further known so little, and their\n",
            "luxerens being riped in any\n",
            "degree perfect and described in a few classes; a        [379]\n",
            "migrate no Project Gutenberg™ e cells of the earth. But the use of any one; according to \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"animals\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npBMtF65arJa",
        "outputId": "384ebb4b-df74-40c9-8934-cc705939b52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "animals,\n",
            "it is well known, fear to three twigming in each sub-varying group having generally\n",
            "varied and were applicable to its seasons. But the importance of the cref he treather modiﬁcation and leaving ﬂoating produce hybrids.\n",
            "These cases on the opposite sides of almost every quantity; and the research of the two areas, and we can understand how it is that all the forms of life, and which had subsequently better adapted to the inhabitants of other and distant sea-shell Fertility. I have         s he\n",
            "w\n"
          ]
        }
      ]
    }
  ]
}